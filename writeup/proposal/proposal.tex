\documentclass[12pt,a4paper]{article}
%\usepackage{geometry}[paper=a4paper,left=30mm,width=150mm,top=25mm,bottom=25mm]
\usepackage[margin=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\begin{document}
\author{Timothy Trewartha \\
\and
Michiel Johan Baird \\
\and
Supervisor: Hussein Suleman \\
Department of Computer Science \\
University of Cape Town
 }
\title{Spatial Navigation of Cultural Heritage Sites}
\maketitle

\section{Project Description}
The Zamani project, started by the UCT Department of Geomatics, aims to preserve African cultural heritage by documenting heritage sites and producing laser scanned models.

\section{Problem Statement and Research Questions}
\subsection{Is it feasible to support real time viewing of models containing billions of points?}
The UCT Department of Geomatics has indicated that they have difficulties handling the size of some of their models. These laser scanned models of cultural heritage sites are often very large, some of them containing over 8 billion points. Given this vast scale of data, traditional viewing methods and the current hardware and software systems are not able to cope.  Consequently, before viewing or manipulating the data, one must go through a process of decimating the original data by a factor of 10, 100 or more. This compromise is often unacceptable, as one may often require the full original detail. This level of detail is often necessary for cultural heritage sites in order to view details such as cracks and flaws, with a view to preserving the site and preventing damage.
\subsection{No Central Data Repository}
The Geomatics Department also mentioned that they have no central storage location for their many models. Some models are stored on a server, but the server does not have sufficient storage capacity for all thier models. Some models are stored on client machines so that the data is immediately available to be viewed and manipulated as required. Lastly, there are some models that are simply stored on external hard drives if there is no space on the server, and if they are not currently being used. This leads to many issues concerning data consistency, data availability and data safety.
\subsection{Workflow and Data Management}
Geographic Information Science involves the capture, storage, manipulation and analysis
and management of geographic data. This data is very diverse and as such has to be handled
in quite diverse ways. This data gets abstracted into various forms. This presents a
rather unique challenge in managing the data as it could be used by anyone of the research
staff at any point in the process. This data movement is laborious and could benefit from
from automisation.

Workflow Management Systems aim to decompose compilated projects and processes into
small atomic chucks. This decompisition can then be optimised to improve the efficiency.
GIS research projects are generally done with multiperson teams where the work is
done in a parallel fashion. Under these conditions workflow management systems
are optimal.

The aim is to provide a workflow management that is applicable for GIS projects.
This system should be able to: interface with the current systems; track and
manage the workflow; provide local data availabilty and content delivery; and
increases overall efficiency within the dicipline.

\section{Procedures and Methods}
\subsection{Hierarchical Data Structure}
From researching the literature it seems that the most common way of dealing with large point based models containing billions of points is to build a multiresolution datastructure to divide our model into manageable chunks. Initially, we need only a small subset of the number of available points. As we zoom into the model we will need to request more points from the datastructure until the full original detail is available. Using such a level-of-detail structure should enable the Department of Geomatics to view even very large models at interactive frame rates, without having to decimate the original data.
\subsection{Server with 24TB storage capacity}
In order to have a central repository for all the models, we aim to obtain a server with around 24TB of storage capacity. This will enable us to keep all the models in a central location.

\section{Ethical, Professional and Legal Issues}
\subsection{Data Privacy}
The Department of Geomatics has indicated that some of the data collected by the Zamani Project is sensitive and is not to be made freely available. It is important to ensure that during the course of this project this wish is respected and that nothing is done to compromise the privacy of sensitive data.

\section{Related Work}
\subsection{Hierarchical Data Structure}
Common methods for structuring 3D data include octrees \cite{interactivepointclouds}, R-trees \cite{rtree}, bounding sphere hierarchies \cite{qsplat}, and Hilbert Space Filling Curves \cite{hilbert}, each with their own advantages and disadvantages. Based on the experimental results of each method, a dynamic octree structure seems to have the best performance \cite{interactivepointclouds}. Using this datastructure the authors were able to achieve interactive walkthroughs of a data set with 2.2 billion points totalling 63.5GB.

\section{Anticipated Outcomes}

\section{Project Plan}
\subsection{Risks}
\subsubsection*{Network Constraints}
One of the core functionalities of the system would be to provide
content delivery of data that is required for a specific task. Providing
this local data allows the task to get completed without unnessesry
fetching delays. There is a risk that this content delivery system
could saturate the network. This would cause the system to be slow
and unusable.
\subsubsection*{Middleware}
For this project to be successful, the WFMS it would have to interface
heavily with existing software used to perform GIS operations. This will
require large amounts of middleware to be developed that understand the
the input and output formats of this software. Since many of these
formats are propriatary a significant amount of effort will have to
be made for the sytem to function. If these formats can not be intergrated
it presents a huge risk to the project.
\subsubsection*{Hardware Limitations}
\subsubsection*{Large Indices}
When indexing the models we will have to generate a significant amount of data. Given that many of the models are already very large, these indices might become unfeasibly large. Dealing with such large indexes will be an important part of the project and we will have to deal with this risk.
\subsubsection*{Integration with Existing GIS Software}
The hierarchical datastructure required as part of this project aims to facilitate level of detail streaming and realtime interaction. However, ideally one should not have to re-implement tools which are already available such as ArcGIS. We aim to integrate our datastructure into a pre-existing software package to prevent unnecessary work. However, this may be difficult and there are several associated risks such as, unavailability of source code, lack of documenation for the software, and potential copyright license infringement.
\subsubsection*{Indexing takes too long}
In the literature it had been noted that indexing the 3D data requires a significant amount of time \citep{interactivepointclouds}. While it is hoped that this will not be a problem, steps will have to be taken to ensure that the duration of the indexing process does not pose a risk to the completion of our project. It will also be important to allow time for the possible event of a systems failure, in which case we would have to resart the indexing process.
\subsection{Timeline, including Gantt chart}
We need a nice program for creating Gantt charts
\subsection{Resources required}
\subsubsection*{Hardware}
\subsubsection*{Geographic Data}
The Department of Geomatics has indicated that they are willing to make their data available for the purposes of this project. It will be important to obtain the models at an early stage as any delays in obtaining the models will delay the entire project.
\subsection{Deliverables}
\subsubsection{GIS Workbench}
The core of the project is to produce a GIS workbench
\subsubsection{Data Flow Facilitator}
\subsubsection{Integration with WFMS}
Workflow Management System
\subsubsection{Hierarchical Data Structure}
\subsubsection{Level of Detail Streaming}
\subsection{Milestones}
\subsubsection{Architectural Model Streaming}
\subsubsection*{Datastructure Implemented}
\subsubsection*{System is able to render large models}
\subsubsection*{System is able to stream large models from the server}
\subsubsection{Workflow and Data Management}
\subsubsection{Combined}
\subsection{Work Allocation}
Project is well divided already, we know who's doing what.
\section{Conclusion}




\bibliographystyle{apalike}
\bibliography{bibliography.bib}	
\end{document}
