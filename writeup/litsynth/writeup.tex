\documentclass[11pt,twocolumn]{article}
\usepackage[cm]{fullpage}
\usepackage{paralist}


\title{Scientific Workbench and Workflow management for GIS workflow}

\author{
    Michiel Johan Baird \\
        Department of Computer Science \\
        University of Cape Town
}

\date{\today}

\begin{document}
\maketitle
\begin{abstract}
    Automated workflow systems have been successfully implemented
    across various disciplines, including Scientific and business
    workflows. This is an overview of what has has been done
    in the field of building these systems and pays special attention
    to building a Scientific Workbench. It focusses of what
    has been done in the past, highlights some the methods used
    as well as the lessons learn during these implementations.

    It also looks at how these principles could be applied
    specifically to GIS workflow by giving an overview of the
    structure of the field. It seeks to find an appropriate
    mapping to these systems using known principles of SOA and
    grid computing.

    This is then illustrates that this solution is highly applicable
    to GIS workflow, provided the necessary middle-ware can be made
    to facilitate integration.
\end{abstract}
\section{Introduction}
    Automated workflow management has been in wide use across
    various disciplines since the concept was formalised in in
    1996\cite{springerlink:10.1007/BF00136712}. Successful systems
    have been implemented across various fields including banking,
    pharmaceuticals and various others
    \cite{Brahe:2007:SWW:1316624.1316661,5407993}.

    This has been very successful in the field of science as
    the process can be rerun on different sets of data.\cite{4721191}
    This not only aids in reproducibility but also gives
    clear direction and saves time. This is done by efficiently
    abstracting the operations of the flow and allowing it
    to be automatically handled.

    Geographic information Systems(GIS) is the field that
    concerns itself with the organisation and representation
    of geographic data, for the purpose of querying it and
    making considered decissions off of the data
    \cite{DiMartino:2007:TAG:1341012.1341081}. This
    seems to lend itself to possibly lend itself to being
    effectively applied to a workflow system.

\section{Overview}
    A workflow management system, consists of definitions
    on how a set of tasks should be executed
    \cite{springerlink:10.1007/BF00136712,vanderAalst2002125}.
    The overall procedure gets defined by the following
    components, actors, roles, responsibilities and
    obligations, tasks, activities, conceptual structures
    and resources.

    A real life problem or task can then be broken up to these
    components in such a way that the tasks represent a flow
    network. These tasks then connect to the actors and resources
    via the other components\cite[p.~4]{Taylor:2006:WES:1196459}.
    This aims to give a clear direction to a project.

    The initial system however almost immediately failed
    due to the fact that the system was far to rigid and
    more often than not change within the system was
    required.\cite{Suchman:1983:OPP:357442.357445}.

    These changes come from a number of sources including:
    ill-specification of initial problems, change in actors
    or resources, exceptions that occur and new requirements.
    Adaptive workflow systems were proposed to solve this
    problem by providing a mechanism for allowing change in
    the system. This allows processes to be extended,
    replaced or re-ordered. It also adds the ability change
    already running tasks by providing restart, transfer and
    proceed options\cite{vanderAalst2002125}.

    Scientific workflow management has also been very
    successful as it fits in very nice with how experiments
    are defined, and more importantly reused. Another
    benefit that was quickly discovered was that it also
    allowed researches to trade work flows making the
    replication of results much easier than they were
    previously. Keys to this success were that the workflow
    systems were made to fit the researchers, quick response
    to adding required features when needed, listening
    to user input and making sharing of workflows as easy as
    possible\cite{4721191}.

    Such a system has also been applied in fields that
    operate on large data sets, as would be the case if
    applied to GIS problems. Workflow systems were found
    to work well in the management of getting this data
    processed. Applying the concept to Observational
    astrophysics, it revealed that it could be used
    to identify bottle necks that could be optimised.
    Further it was used to automatically ensure local
    access of large files when it needed to be processed.
    \cite{Aragon:2009:WMH:1529282.1529491}

\section{Geographic Data}
    GIS concerns tasks itself with the collection, organisation
    and query of geographic data. This data includes but
    is not limited to landscapes, coordinate data, building models,
    statistics, pictures, textures and routes. This
    is a very broad set of data, varying from very large to very small,
    that has no uniform method  of being efficiently dealt with.

    The processing of this data can vary from human, to software
    processing. Various Web applications have been written
    to facilitate the tasks that need to be accomplished.
    These are known as WebGIS\cite{DiMartino:2007:TAG:1341012.1341081}.

    A key realisation with the usage of this data is that
    is the same data is used across various applications,
    to create particular abstractions. The core data is
    seldom change instead a new abstraction layer is added
    on top of it. This allows that the data can be thought
    of as a graph. Where the nodes represent either a data,
    or abstraction element, and the edges represents the
    functions/task required to create the particular abstraction
    as a set of topological
    relationships. This can be effectively used to provide
    high levels of GIS
    interoperability\cite{ElAdnani:2001:MLF:512161.512177}.

\section{Implementations}
    There are various products available that can compose
    scientific workflows. \emph{The Trident workbench}
    \cite{Simmhan:2009:BTS:1673063.1673121} is an open
    source workflow management system developed by Microsoft
    Research that also adds middleware services and a
    composition interface. Trident builds work flows of control
    and data flows, off of built-in, user defined activities and
    nested subflows.

    The flows are represented using XOML (XML Specification) while
    the activities are stored as a set of sub routines. Trident
    can be used on a local system, remote systems and even clusters.
    Queries on the system can be performed using LINQ.
    \cite{Simmhan2011790}

    \emph{Kepler} is another scientific workflow
    management system, that
    provides workflow design and execution. Actors are designed
    to perform independent tasks that can either be atomic or
    composite. Composite actors(subflows) are consists of multiple
    atomic actors bundled together. Actors can consume data and
    produce output, called tokens. Actors communicate tokens with
    each other via links. The order of execution and the links are
    defined by an independent entity called the director. As a
    consequence the workflow can either be executed in a
    sequential or parallel manner. Kepler effectively separates
    the workflow from it's execution allowing for easy batch
    execution. Actors can easily be exported and shared.
    \cite{Wang:2009:KHG:1645164.1645176}

    \emph{Taverna} is another scientific workbench that supports
    application-level work flow and does not focus on scheduling
    as much others. Taverna has a strong focus on workflow
    sharing. Taverna is quite popular, since there exists
    a social network, designed to facilitate workflow sharing
    between scientists. Services are linked to the model to
    execute the various tasks. Taverna can be used in such
    a way that it can utilize all the services a client has
    to facilitate the flow by easily adding services. The
    taverna language is a simple data-flow language called
    the Simple Conceptual Unified Language(Scufl) that can
    be encoded to XML\cite{4721191}.

    In order for these workbenches to be successful there needs
    to exists a high level of interoperability between the
    workflow management and the services that are required.
    However due to the fact that there is a relatively  high
    chance of failure building this interoperability into the
    services as a core component is an extremely high risk
    and therefore is not typically done. Cheaper ways of
    doing this is providing middleware that can wrap around
    the service to provide the required interfaces
    \cite{Shegalov:2001:XWM:767132.767139}.
    This need for interoperability has lead to the
    popularisation SOA(Service Orientated Architecture).
    Although the concept has been around since the 1970s,
    it has only recently gained favour due to Web services.
    It should be noted that SOA is not an implementation,
    but rather an \emph{Architectural Model}
    SOA refers to a collection of loosely coupled services,
    that individually carry out a particular process. Each
    service should have a well defined interface with self
    contained functionality. It should allow other applications
    or services to use this functionality without the underlying
    technical details. These services should be hidden from the
    end-user and its usage should be platform independent.
    \cite{Sanders:2008:SSA:1400549.1400595}.

    By using the concepts from SOA, a workflow system can
    be built that automatically uses these web-services
    to facilitate both the data and control flow using,
    well defined interfaces such as XML/JSON.
    \cite{Shegalov:2001:XWM:767132.767139}. With the
    advancement of WebGIS, it would seem very promising,
    that such a system could be developed, to facilitate
    Geographic Processing tasks.


\section{Case Studies}
    The next section will look at two instances where
    workflow management systems were implemented and used.
    These case studies will look at both a business and a
    scientific application.
    \subsection*{Danske Bank}
    The workflow management system at \emph{Danske bank} was
      incrementally implemented as there system moved
      from a manual system.

      The system was slowly introduced when the client
      packages became to time consuming for the customer
      advisors and was sup-optimal for the customers.
      This was then replaced by a document that contained
      a description of the package, this was then shipped
      off to back office workers that assembled the packages
      from the document, as a sort of primitive workflow system.
      This then slowly developed to include web-services,
      and almost full atomisation. This rapidly expanded
      to almost every function of the bank and increased
      productivity drastically.

      Several lessons were learned during the process that
      is applicable to other work flow systems. When work
      was divided purely from an efficiency point of view
      the workers became complacent as they felt that they
      did not understand the overall mechanism and felt that
      they were not involved. They also discovered that the
      system did not handle change very well. And this change
      was as expensive as it was inevitable the system had
      to be adapted to handle this change. The success of the
      system is mainly attributed to the interruptibility and
      close relationship between the users and the developers
      \cite{Brahe:2007:SWW:1316624.1316661}.

    \subsection*{OrthoSearch}
      \emph{OrophoSearch} is a workflow,
      built on \emph{Kepler} that is designed to work on
      work on data in the field of Bio Informatics. This
      was used in the the dicipline of \emph{Neglected Diseases}
      which has the potential to kill millions of people.

      A pipeline was was created to represent the workflow
      of this research. This pipeline was then implemented
      using \emph{Perl} scripts. This solution did not meet
      some of the original requirements, nor did it provide
      the desired level of abstraction.

      The system was moved to \emph{Kepler} as it addressed
      the requirements better including: \begin{inparaenum}[(i)]
      \item Workflow definition and Design; \item workflow execution
      control; \item fault tolerance; \item intermediate data management;
      and \item data provenance support. \end{inparaenum}

      This approach turned out to be much more successful. With
      its flexibility, stability and grid enabled features, it
      addressed most of the problems that the manual system had.

      Although the system was not without its hickups and changes
      the integration with Kepler provided the workflow with the
      much needed direction and increased overall productivity
      drastically.\cite{daCruz:2008:OSW:1363686.1363983}


\section{Conclusion}
   The field of GIS concerns itself with a vast amout of Geographic
   data. This data comes in various sizes and as such different
   methods of handling and transfering would need to be used to
   facilitate dataflows within the system. It was also found that
   there are a large number of transformations that workflow would
   need to support.

   The work however is done in very distributed mannor which allows
   for a very effective mapping onto a grid based computing solution.
   Provided middleware can be developed to support the systems that
   are used. This would allow for effective Content Delivery Network
   that provides data on demand where it is needed on the grid
   \cite{Montella:2007:UGC:1272980.1272995}.

   A workflow system would appear to be highly effective in this
   field, as it supports the nature of the science extremely well,
   It would allow for effective automatisation of some of the
   functions and would be able to remove a large amount of the
   problems associated with Content Delivery.
   \cite{Withana:2010:VWE:1851476.1851586}




\bibliography{../references}{}
\bibliographystyle{acm}

\end{document}


